---
title: "Datacamp Tutorial: Loading Data (2)"
description: ""
author: ""
date: 2019-01-20T10:59:16-05:00
tags: [r, tutorials, jsonlight, dbConnect]
---
```{r, message=FALSE, warning=FALSE}
library(tidyverse)
library(dbConnect)
library(jsonlite)
```

In this mundane but very important course, I reviewed some packages I'm familiar with, was introduced to new ones, and learned how to use json filetypes and import data directly from the web by calling apis.

##1. Connecting to databases using dbConnect, SQL

1.1: Connect to the database
```{r}
con <- dbConnect(RMySQL::MySQL(), 
                 dbname = "tweater", 
                 host = "courses.csrrinzqubik.us-east-1.rds.amazonaws.com", 
                 port = 3306,
                 user = "student",
                 password = "datacamp")
```

1.2 List and import tables

```{r}
dbListTables(con)

#import single table
dbReadTable(con, "tweats")

table_names <- dbListTables(con)


#import all tables

lapply(FUN = dbReadTable, table_names, conn = con)

```

1.3 Make SQL queries to the database from R
Helpful approach for when dealing with large sets of data and only subsets are required.

```{r}
dbGetQuery(con, "SELECT tweat_id FROM comments WHERE user_id = 1")

dbGetQuery(con, "SELECT message FROM comments WHERE tweat_id = 77 AND user_id > 4" )

# Can grab glimpses of the queries being made by sending and fetching:

res <- dbSendQuery(con, "SELECT * FROM comments WHERE user_id > 4")

dbFetch(res) #can also set `n =` arguments to limit results

```

1.4 Disconnecting from database

```{r, eval=FALSE}
dbDisconnect(con)
```


##2. Importing data from the web using utils, readr, and httr

a. Direct download of flat files using readr or utils:

```{r, eval=FALSE}
url_csv <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/swimming_pools.csv"

pools <- read_csv(url_csv)
```

b. Downloading files using https and http:

```{r, eval = FALSE}
# https URL to the wine RData file.
url_rdata <- "https://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/wine.RData"

# Download the wine file to your working directory
download.file(url_rdata, "wine_local.RData")

# Load the wine data into your workspace using load()

load("wine_local.RData")

```

c. Downloading files using httr::

```{r, eval=FALSE}
url <- "http://www.example.com/"
resp <- GET(url)

#can download content as "raw", "character", or "R object"
raw_content <- content(resp, as = "raw")

#downloading json file with GET:
url <- "http://www.omdbapi.com/?apikey=72bc447a&t=Annie+Hall&y=&plot=short&r=json"
resp <- GET(url)

# resp as text
content(resp, as = "text")

```


d. Importing and sending json files using jsonlite::

```{r, eval=FALSE}
#json structure
wine_json <- '{"name":"Chateau Migraine", "year":1997, "alcohol_pct":12.4, "color":"red", "awarded":false}'

# Convert wine_json into a list: wine
wine <- fromJSON(wine_json)

#import json files directly from API calls
quandl_url <- "https://www.quandl.com/api/v3/datasets/WIKI/FB/data.json?auth_token=i83asDsiWUUyfoypkgMz"

# Import Quandl data: quandl_data
quandl_data <- fromJSON(quandl_url)


#sending files back to json format
url_csv <- "http://s3.amazonaws.com/assets.datacamp.com/production/course_1478/datasets/water.cs"

# Import the .csv file located at url_csv
water <- read.csv(url_csv, stringsAsFactors = FALSE)

# Convert the data file
water_json <- toJSON(water)

```

##3. Importing data from statistics software using haven  

*SAS*

```{r, eval=FALSE}
haven::read_sas("datafile.sas7bdat")
```

*STATA*  
With STATA, files come with associated "label" values, which R converts into unique numerics. These should be converted to factors on import. Can see here how the Date column looks before and after conversion: 
```{r, eval=TRUE}
sugar <- haven::read_dta("http://assets.datacamp.com/production/course_1478/datasets/trade.dta")

# Structure of sugar
str(sugar)

# Convert values in Date column to dates
sugar$Date <- as.Date(as_factor(sugar$Date))

# Structure of sugar again

str(sugar)
```


*SPSS*  

```{r, eval = FALSE}
traits <- haven::read_sav("http://staff.bath.ac.uk/pssiw/stats2/personality.sav")

# Summarize traits
summary(traits)

# Print out a subset

head(subset(traits, "Extroversion" > 40 & "Agreeableness" >40), 5)
```








