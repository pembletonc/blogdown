---
title: "Cleaning, Gathering, excel_numeric,  and na_if()"
author: "Corey Pembleton"
date: "July 11, 2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(janitor)
library(lubridate)
library(readxl)

bytes <- file.size("sep-gather-mutate.Rmd")
words <- bytes/10
minutes <- words/200

```

Reading Time: `r round(minutes)` minutes  

#The thing with messy data....

Working in international development, like many other fields, means being the only person who programs instead of using a spreadsheet software such as Microsoft Excel. This has some clear advantages, like being able to automate tasks and make pretty charts, and some challenges - such as perpetual cleaning of data to make it machine-friendly for easy processing. This post is an example of how to efficiently clean messy excel charts to prepare for future processing.

##



##Clean data is happy data

In this case, I have a several common issues to address:

1. Multiple empty rows
2. Names too long, contain non-alphanumeric characters
3. Dates showing up in excel-numeric format
4. Typos
5. Multiple pieces of information in a single cell
6. Empty, but not "NA" cells

These issues can all be addressed in a single ```dplyr``` pipeline using ```janitor``` and ```lubridate``` for the dates. 

###1. Remove empty rows

When people work in excel, it is common to leave spaces between rows to make it easier on the eyes, but this unfortunately is inefficient in automated processing.

This:
![](/img/Spreadsheet_example.png)


Looks like this to a computer:

![](/img/r-spreadsheet-view.png)

Something which can be easily fixed by removing the "empty" rows as soon as the data is imported with the ```remove_empty()``` function:

```{r}
media <- read_excel("African Media Coverage.xlsx") %>% remove_empty(which = "rows")

```

Next, changing names to be more analysis-suitable:

```{r}
#change the names to remove spaces and other funny characters
media <- media %>%
  rename(Title = `Article Title`, 
         Link = `Article Link`,
         Summary = `Summary (if already available)`,
         Origin = `Outlet Origin`,
         Reach = `Outlet Reach`,
         Mentions = `Organizations Mentioned (Separate by comma)`) 
```
  
Follwoing this, we can remove the pesky excel numeric and convert to Date format using the ```janitor``` ```excel_numeric_to_date()``` function:

```{r, warning = FALSE, message=FALSE}  
media <- media %>%
  mutate(Date = excel_numeric_to_date(as.numeric(Date))) 
```

Until this point, the tasks completed have been oriented around making the data suitable for R when it was already suitable for human-use in excel. This next stage, makes the data more suitable for both. 

The column "mentions", which contains human-input instances each time a certain organization was mentioned in a media article, consists of a list of names seperated by a comma. This means that while I could pull out instances where organization names are mentioned using the ```stringr``` ```str_detect()``` function, I couldn't analyze these organizations individually, and there would be double counting, and potentially other errors. 

To split them, I first separate the column into individual columns using ```separate()```:

```{r, warning = FALSE, message=FALSE}
media <- media %>%
  separate(Mentions, into = c("Org_1", "Org2", "Org3", "Org4", "Org5",
                              "Org6", "Org7", "Org8", "Org9", "Org10"), sep = ",")
```

which results in multiple columns with temporary names, with each column containing the name of one of the organizations mentioned in the article.

![](/img/NA_example.png)

These can then be gathered together into a single "Organization" column, which means that each of the web-links and other columns will be repeated for each of the Organizations. This is acceptable, as there are no instances when these will need to be combined further. 

```{r}
media <-  media %>%
  gather(c("Org_1", "Org2", "Org3", "Org4", "Org5",
           "Org6", "Org7", "Org8", "Org9", "Org10"), key = Position, value = Organization) %>%
  select(-Position)
  
```  


Upon inspection, it is clear that there are some issues regarding how it was parsed during the seperating, spreading and gathering. Some columns correctly contain organization names (1), some are NA (2), and others contain blank character spaces (3). 

![](/img/org-column.png)

After help from the rstats community on twitter and through problem solving, I found by nesting ```str_trim()``` within mutate I could remove whitespace, assign "NA" to the empty columns using ```na_if()```, and remove all ```NA``` in the column with ```na.omit```. 

```{r, echo=FALSE}

blogdown::shortcode('tweet', '1016789531297660928')

```


```{r}
media <- media %>%
  mutate(Organization = str_trim(Organization, side = "both"),
         Organization = na_if(Organization, "")) %>%
  na.omit(Organization)

```

Excellent, I have now addressed nearly all the issues in the dataset to begin the analysis.

1. ~~Multiple empty rows~~
2. ~~Names too long, contain non-alphanumeric characters~~
3. ~~Dates showing up in excel-numeric format~~
4. ~~Multiple pieces of information in a single cell~~
5. ~~Empty, but not "NA" cells~~
6. Typos

I quickly realized that there are typos in some of the organization names, which can be rectified by using ```case_when()```. ```case_when()``` allows me to [vectorise multiple ```if``` and ```else if``` statements](https://www.rdocumentation.org/packages/dplyr/versions/0.7.6/topics/case_when) at once, helpful for fixing multiple names in one shot. The downfall of this approach is that it requires searching for the names and finding the mispelt ones. I did this creating a ```str_detect()``` keyword search and ```summarise()``` by organizaton to see where multiples existed. 


```{r, message=FALSE}
media <- media %>%
  mutate(Organization = case_when(
    Organization == "Bill and Melinda Gates Foundation" ~ "Bill & Melinda Gates Foundation (BMGF)",
    Organization == "Bill & Melinda Gates Foundation" ~ "Bill & Melinda Gates Foundation (BMGF)",
    Organization == "Alliance for Green Revolution in Africa (AGRA)" ~ "Alliance for a Green Revolution in Africa (AGRA)",
    Organization == "Alliance for a Green Revolution in Africa" ~ "Alliance for a Green Revolution in Africa (AGRA)",
    Organization == "Alliance for a Green Revolution in Afirca" ~ "Alliance for a Green Revolution in Africa (AGRA)",
    TRUE ~ as.character(Organization)
  ))

```

Now that the last data cleaning issue is crossed off the list, I'm ready to scrape the websites and continue with further analysis!


