---
title: "Media Monitoring Analysis in R: An Overview"
author: "Corey Pembleton"
date: '2018-12-15'
output: html_document
slug: media-monitoring-analysis-using-r
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

As a consultant, I have to wear many different hats. Some days I'm munging a portfolio, another leading a focus group, and on another catching a flight to Kathmandu to participate in a workshop. It's the beauty of my job, and keeps things spicy. Not doing the same thing all the time means I'm learning constantly, which is what this story is about.  

A client with a well-established media presence wanted a "traditional and social media analysis" to understand the reach and impact of their program. We helped with the analysis and details, but they ended hiring a specialist on the subject to collect the data, give us the stats, etc. I had a feeling that with a bit of looking around, I could pull of a similar piece of work.    

<<<<<<< HEAD
## Media monitoring: the main factors to consider
In general there are a few things people commonly want out of a media monitoring analysis: **Reach** (how many are seeing your content), **Engagement** (who are your followers?), and **Content analysis** ([covered here]()). 

### Tools used
=======
In general there are a few things people commonly want out of a media monitoring analysis: **Reach** (how many are seeing your content), **Engagement** (who are your followers?), and **Content analysis** ([covered here]()). 

>>>>>>> 659c8fe74a5b8dec0962bf1d99eb10ac31bbdd95
I'll use the ```rtweet``` package developed by [M. Kearny](https://mikewk.com/) for this post, and take some ideas from helpful sources on the topic and other brilliant programmers doing fun-useful things with the package(like [here](https://rud.is/books/21-recipes/) and [here](http://rpubs.com/ben_bellman/rtweet_tidygraph). 

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(rtweet)
library(ggraph)
library(igraph)
library(scales)
```

## Reach
How often someone tweets can be a simplistic determination of their reach, especially when considering the amount of followers they have. Following the ```rtweet``` vignette, collecting tweets is an easy process either by user or topic:

```{r, cache=TRUE}
tweets <- search_tweets("#COP24", n = 1500, include_rts = FALSE,
                    retryonratelimit = FALSE)

```

Here, we can visualize the 1500 tweets that include the hashtag "COP24" in 30 minute intervals using the ```ts_plot()``` function for plotting timelines:

```{r, echo = FALSE}
ts_plot(tweets, "30 minutes") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold")) +
  labs(
    x = NULL, y = NULL,
    title = "Frequency of #COP24 Twitter statuses",
    subtitle = "Twitter status (tweet) counts aggregated using 15-minute intervals",
    caption = "\nSource: Data collected from Twitter's REST API via rtweet"
  )
```

Understanding tweet "reach" can be accompanied by understanding the relationship between who is "retweeting" the same tweets. Using the ```ggraph``` package, the resultant collected tweets can be filtered and unnested according to retweets by screen name, and converted into a graph object using ```igraph```.  
```{r, eval=FALSE}

graph <- filter(tweets, retweet_count > 0) %>% 
  select(screen_name, mentions_screen_name) %>%
  unnest(mentions_screen_name) %>% 
  filter(!is.na(mentions_screen_name)) %>% 
  igraph::graph_from_data_frame()

#clean up the names, and only use the names with X amount of retweets
V(graph)$node_label <- unname(ifelse(degree(graph)[V(graph)] > 10, names(V(graph)), "")) 
V(graph)$node_size <- unname(ifelse(degree(graph)[V(graph)] > 10, degree(graph), 0)) 
```

With a resulting graphical representation showing the users who have been most commonly re-tweeted (remembering that this is for a small set of tweets only, changing the size of the tweet collection will drastically change the results).

```{r, echo = TRUE,   eval=FALSE}
ggraph(igraph, layout = 'linear', circular = TRUE) + 
  geom_edge_arc(edge_width=0.125, aes(alpha=..index..)) +
  geom_node_label(aes(label=node_label, size=node_size),
                  label.size=0, fill="#ffffff66", segment.colour="springgreen",
                  color="slateblue", repel=TRUE, fontface="bold") +
  coord_fixed() +
  scale_size_area(trans="sqrt") +
  labs(title="Retweet Relationships", subtitle="Most retweeted screen names labeled.\nDarkers edges == more retweets. Node size == larger degree") +
  theme_graph() +
  theme(legend.position="none")
```

![](/img/graph_relationships.png){ width=200% }


This gives us some idea of who are the most visible actors in the media set being analyzed, and opens the door for future engagement potential - if some names stand out as being active in certain topics, how can they be better engaged with to extend the client's reach?  


## Engagement - Influence

<<<<<<< HEAD
One way to determine engagement is through an interpretation of the level of influence single tweets, campaigns, or accounts have based on the interaction by followers. For a full discussion on influence analysis approaches using social media, see [Meng Han,Yingshu Li ](http://aimsciences.org/article/doi/10.3934/mfc.2018010)
=======
One way to determine engagement is through an interpretation of the level of influence single tweets, campaigns, or accounts have based on the interaction by followers.
>>>>>>> 659c8fe74a5b8dec0962bf1d99eb10ac31bbdd95

Like many of the useful functions found in ```rtweet```, ```get_followers()```,  allows me to count the followers of followers, a pseudo-primary influence measure. This approach is a quick take from [rud.is](https://rud.is/books/21-recipes/crawling-followers-to-approximate-primary-influence.html), and like he states should further integrate favourites and retweets for a more accurate measure. Reusing the "influence_snapshot" function, I can create a rapid measure of potential overall influence, by user:

```{r, echo=TRUE, eval = TRUE}
influence_snapshot <- function(user, trans = c("log10", "identity")){
  user <- user[1]
  trans <- match.arg(tolower(trimws(trans[1])), c("log10", "identity"))
  
  user_info <- lookup_users(user)
  
  user_followers <- get_followers(user_info$user_id)
  
  uf_details <- lookup_users(user_followers$user_id)
  
  primary_influence <- scales::comma(sum(c(uf_details$followers_count, user_info$followers_count)))
  
    plot <- 
      filter(uf_details, followers_count > 0) %>% 
    ggplot(aes(followers_count)) +
    geom_density(aes(y = ..count..), color = "lightslategray", fill = "lightslategray",
                 alpha = .66, size = 1 ) +
    theme_minimal() +
    scale_x_continuous(expand = c(0,0), trans = "log10", labels = scales::comma, limits = c(1, 10000000)) +
    scale_y_continuous(labels = scales::comma) +
  labs(
      x = "Number of Followers of Followers (log scale)", 
      y = "Number of Followers",
      title = sprintf("Follower chain distribution of %s (@%s)", user_info$name, user_info$screen_name),
      subtitle=sprintf("Follower count: %s; Primary influence/reach: %s", 
                       scales::comma(user_info$followers_count),
                       scales::comma(primary_influence))
    ) +
    theme(axis.title.x = element_text(hjust = 1, size = 8, face = "bold"))
    
  
  print(plot)
  
  return(invisible(list(user_info=user_info, follower_details=uf_details)))
}
  
```


Which does two things: 1) it collects the amount of "followers of followers" and 2) it produces a density graph with the results:
```{r, fig.height= 4, fig.width=7}
influence_snapshot("coreypembleton")

```

Or, looking at an account with far more followers than my own modest following:

```{r, fig.height= 4, fig.width=7}

influence_snapshot("hadleywickham")

```

This "influence snapshot" is limited in what meaning can be extracted. For targeted campaigns, more accurate counts of actual influence can be derived based upon interactions, and what level of reach those interactions have.


## Qualitative Content Analysis 

<<<<<<< HEAD
Qualitative Content analysis, a well-established topic in media analysis, is a means of studying people's experiences of those receiving and creating media messages (1). Historically this type of analysis is completed by ethnographers and researchers reviewing, coding and processing media content as a means of gaining greater understanding into its meaning, such as the senitment of the text. Being such a foundational topic, I continue the discussion further [here](http://coreypembleton.netlify.com/dev-eval/media-monitoring-analysis-content-analysis), and the nuances around influence and sentiment.
=======
Qualitative Content analysis, a well-established topic in media analysis, is a means of studying people's experiences of those receiving and creating media messages (1). Historically this type of analysis is completed by ethnographers and researchers reviewing, coding and processing media content as a means of gaining greater understanding into its meaning, such as the senitment of the text. Being such a foundational topic, I continue the discussion further [here](). 
>>>>>>> 659c8fe74a5b8dec0962bf1d99eb10ac31bbdd95

## Lessons Learned

Media content analysis is fundamental for organizations that want to understand the impact of their communications efforts beyond the statistics provided by the platforms themselves. I believe now that by focusing on several main components, such as reach, influence, and content analyses, there can be some very useful insights obtained. Every media analysis cannot contain everything, so anytime it is performed, the clients' needs should be specifically targeted and met.







(1) D.E. Polkinghorne. *The Oxford Handbook of Media Psychology*. Edited by Karen E. Dill




