---
title: "Media Monitoring Analysis in R: An Overview"
author: "Corey Pembleton"
date: '2018-12-15'
output: html_document
slug: media-monitoring-analysis-using-r
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

As a consultant, I have to wear many different hats. Some days I'm munging a portfolio, another leading a focus group, and on another catching a flight to Kathmandu to participate in a workshop. It's the beauty of my job, and keeps things spicy. Not doing the same thing all the time means I'm learning constantly, which is what this story is about.  

Clients often want "traditional and social media analysis" performed to understand the reach and impact of their programming, a specific campaign, a targeted advocacy programme, or a variety of other reasons. Traditionally for evaluators this would mean reading over a list of shared documents or media files, but in the 21st century media analysis almost has to go a step further. What that next step looks like can be very wide ranging, but a good start is in gauging social media impact and influence, which is what this post explores.

## Media monitoring: the main factors to consider
In general there are a few components clients commonly want answered out of a media monitoring analysis: **Reach** (how many people are seeing your content?), **Engagement** (who is engaging with the content?), and **Content analysis** (what is the content and sentiment of the engagement like?). If these main questions can be accurately answered, you'll be more or less on track to understand what their media investments have achieved.

### Tools used

I'll use the ```rtweet``` package developed by [M. Kearny](https://mikewk.com/) for this post, and take some ideas from helpful sources on the topic and other programmers doing fun-useful things with the package, such as [here](https://rud.is/books/21-recipes/) and [here](http://rpubs.com/ben_bellman/rtweet_tidygraph). 

```{r, warning=FALSE, message=FALSE}
library(tidyverse)
library(rtweet)
library(ggraph)
library(igraph)
library(scales)
```

## Reach
How often someone tweets can be a simplistic determination of their reach, especially when considering the amount of followers they have. Following the ```rtweet``` vignette, collecting tweets is an easy process either by user or topic, for example here collecting tweets for two hashtags:

```{r, cache=TRUE}
tweets <- search_tweets("#montreal", n = 1500, include_rts = FALSE,
                    retryonratelimit = FALSE )

#tweets <- search_tweets("#COP24", n = 1500, include_rts = FALSE,
#                    retryonratelimit = FALSE, )

```

Here, we can visualize the 1500 tweets that include the hashtag "COP24" in 30 minute intervals using the ```ts_plot()``` function for plotting timelines:

```{r, echo = FALSE}
ts_plot(tweets, "6 hours") +
  theme_minimal() +
  theme(plot.title = element_text(face = "bold")) +
  labs(
    x = NULL, y = NULL,
    title = "Frequency of #montreal Twitter statuses",
    subtitle = "Twitter status (tweet) counts aggregated using 15-minute intervals",
    caption = "\nSource: Data collected from Twitter's REST API via rtweet"
  )
```

Understanding tweet "reach" can be accompanied by understanding the relationship between who is "retweeting" the same tweets. Using the ```ggraph``` package, the resultant collected tweets can be filtered and unnested according to retweets by screen name, and converted into a graph object using ```igraph```.  
```{r}

graph <- filter(tweets, retweet_count > 0) %>% 
  select(screen_name, mentions_screen_name) %>%
  unnest(mentions_screen_name) %>% 
  filter(!is.na(mentions_screen_name)) %>% 
  igraph::graph_from_data_frame()

#clean up the names, and only use the names with X amount of retweets
V(graph)$node_label <- unname(ifelse(degree(graph)[V(graph)] > 10, names(V(graph)), "")) 
V(graph)$node_size <- unname(ifelse(degree(graph)[V(graph)] > 10, degree(graph), 0)) 
```

With a resulting graphical representation showing the users who have been most commonly re-tweeted (remembering that this is for a small set of tweets only, changing the size of the tweet collection will drastically change the results).

```{r, echo = TRUE,   eval=FALSE}
ggraph(graph, layout = 'linear', circular = TRUE) + 
  geom_edge_arc(edge_width=0.125, aes(alpha=..index..)) +
  geom_node_label(aes(label=node_label, size=node_size),
                  label.size=0, fill="#ffffff66", segment.colour="springgreen",
                  color="slateblue", repel=TRUE, fontface="bold") +
  coord_fixed() +
  scale_size_area(trans="sqrt") +
  labs(title="Retweet Relationships", subtitle="Most retweeted screen names labeled.\nDarkers edges == more retweets. Node size == larger degree") +
  theme_graph() +
  theme(legend.position="none")
```

![](/img/graph_relationships.png){ width=200% }


This gives us some idea of who are the most visible actors in the media set being analyzed, and opens the door for future engagement potential - if some names stand out as being active in certain topics, how can they be better engaged with to extend the client's reach?  


## Engagement - Influence

One way to determine engagement is through an interpretation of the level of influence single tweets, campaigns, or accounts have based on the interaction by followers. For a full discussion on influence analysis approaches using social media, see [Meng Han,Yingshu Li ](http://aimsciences.org/article/doi/10.3934/mfc.2018010)

One way to determine engagement is through an interpretation of the level of influence single tweets, campaigns, or accounts have based on the interaction by followers.

Like many of the useful functions found in ```rtweet```, ```get_followers()```,  allows me to count the followers of followers, a pseudo-primary influence measure. This approach is a quick take from [rud.is](https://rud.is/books/21-recipes/crawling-followers-to-approximate-primary-influence.html), and like he states should further integrate favourites and retweets for a more accurate measure. Reusing the "influence_snapshot" function, I can create a rapid measure of potential overall influence, by user:

```{r, echo=TRUE, eval = TRUE}
influence_snapshot <- function(user, trans = c("log10", "identity")){
  user <- user[1]
  trans <- match.arg(tolower(trimws(trans[1])), c("log10", "identity"))
  
  user_info <- lookup_users(user)
  
  user_followers <- get_followers(user_info$user_id)
  
  uf_details <- lookup_users(user_followers$user_id)
  
  primary_influence <- scales::comma(sum(c(uf_details$followers_count, user_info$followers_count)))
  
    plot <- 
      filter(uf_details, followers_count > 0) %>% 
    ggplot(aes(followers_count)) +
    geom_density(aes(y = ..count..), color = "lightslategray", fill = "lightslategray",
                 alpha = .66, size = 1 ) +
    theme_minimal() +
    scale_x_continuous(expand = c(0,0), trans = "log10", labels = scales::comma, limits = c(1, 10000000)) +
    scale_y_continuous(labels = scales::comma) +
  labs(
      x = "Number of Followers of Followers (log scale)", 
      y = "Number of Followers",
      title = sprintf("Follower chain distribution of %s (@%s)", user_info$name, user_info$screen_name),
      subtitle=sprintf("Follower count: %s; Primary influence/reach: %s", 
                       scales::comma(user_info$followers_count),
                       scales::comma(primary_influence))
    ) +
    theme(axis.title.x = element_text(hjust = 1, size = 8, face = "bold"))
    
  
  print(plot)
  
  return(invisible(list(user_info=user_info, follower_details=uf_details)))
}
  
```


Which does two things: 1) it collects the amount of "followers of followers" and 2) it produces a density graph with the results:
```{r, fig.height= 4, fig.width=7, eval=FALSE}
influence_snapshot("coreypembleton")

```

Or, looking at an account with far more followers than my own modest following:

```{r, fig.height= 4, fig.width=7, eval=FALSE}

influence_snapshot("hadleywickham")

```

This "influence snapshot" is limited in what meaning can be extracted. For targeted campaigns, more accurate counts of actual influence can be derived based upon interactions, and what level of reach those interactions have.


## Qualitative Content Analysis 

Qualitative Content analysis, a well-established topic in media analysis, is a means of studying the experiences of those receiving and creating media messages (1). Historically, this type of analysis is completed by ethnographers and researchers reviewing, coding and processing media content as a means of gaining greater understanding into its meaning, such as the senitment of the text. Being such a foundational topic, I continue the discussion further [here](http://coreypembleton.netlify.com/dev-eval/media-monitoring-analysis-content-analysis) in greater detail.

## Lessons Learned

Media content analysis is fundamental for organizations that want to understand the impact of their communications efforts beyond the statistics provided by the platforms themselves. I believe now that by focusing on several main components, such as reach, influence, and content analyses, there can be some very useful insights obtained. Every media analysis cannot contain everything, so anytime it is performed, the clients' needs should be specifically targeted and met.







(1) D.E. Polkinghorne. *The Oxford Handbook of Media Psychology*. Edited by Karen E. Dill




