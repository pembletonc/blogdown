---
title: "Analyzing Twitter Data Using Tidytext, TwitteR and Lubridate"
author: "Corey Pembleton"
date: "6/18/2018"
output: html_page()
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r, echo=FALSE, warning=FALSE, message=FALSE}
library(twitteR)
library(tidytext)
library(tidyverse)
library(graphTweets)
library(kableExtra)
library(lubridate)
library(ggridges)
library(wesanderson)
library(egg)

bytes <- file.size("tidy-text-twitter.Rmd")
words <- bytes/10
minutes <- words/200

```

```{r, warning=FALSE, message=FALSE, echo=FALSE}
tweets <- read_csv("tweets.csv")

```

Reading Time: `r round(minutes)` minutes  


## Tidying twitter data with tidytext and twitteR

Automated text analysis for sentiment, word frequencies, and content has long been the dream of qualitative scientists, but it still remains somewhat elusive when trying to extract meaningful interpretations of massive amounts of text using machine-based approaches. One approach to perform this type of analysis in R is with the newly developed [text mining with R](https://www.tidytextmining.com/) ```tidytext``` tools developed by [Julia Silge](https://twitter.com/juliasilge) and [David Robinson](https://twitter.com/drob). As included in the tutorial / vignette, the tidytext library can used to perform text analysis on tweet content, which is what I would like to do in this post. 

### Choosing a topic to analyze

I find global politics interesting enough, and the trend of authorities increasing their presence on social media provides a unique and open source of information to interpret a leader’s talking points, and to see how these can be associated with certain sentiments, or historical points of interest. 

### Selecting world leaders
When I started doing some research into selecting which leaders should be included, I found that there is a [severe lack of inclusion of women in lists stating the top "influencers" on social media](https://www.newstatesman.com/politics/feminism/2017/12/why-are-women-politics-less-authoritative-twitter-because-men-are-less), and that both men and women interact with male politicians and political journalists far more (5 times more) than their female counterparts. 


As such, I can't only use "top influential politician lists", such as [this 'twiplomacy' list](https://twiplomacy.com/ranking/50-world-leaders-interactions-twitter/) of world leaders with the most twitter interactions, so I will instead be much more selective to attain gender parity in the analysis.


```{r, echo=FALSE}

Leaders <- tribble(
  ~Name, ~`# of interactions / followers`, ~Country, ~Username,
  #----/---------------------/--------
  "N. Modi", 42000000, "India", "PMOIndia",
  "Pope Francis", 14000000, "Vatican", "Pontifex",
  "R.T. Ergodan", 13000000, "Turkey", "RT_Erdogan",
  "J. Trudeau", 7000000, "Canada", "JustinTrudeau",
  "E. Macron", 7000000, "France", "EmmanuelMacron",
  "S. Swaraj", 2000000, "India", "SushmaSwaraj",
  "M. Bachlete", 713000, "Chile", "mbachelet",
  "T. May", 560000, "United Kingdom", "theresa_may",
  "R.L. Abdullah",10900000 ,"Jordan" ,"QueenRania",
  "C. Kirchner", "5380000", "Argentina", "CFKArgentina"
  )
```

Seeking a good geographic, linguistic, political and gender balance led me to this final list of world leaders:

```{r, echo=FALSE, message=FALSE}
kable(Leaders) %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))
```

Mining their tweets and converting into a dataframe is smooth process with the ``` twitteR``` package, providing a single usable source, easily updated, of each users' tweets.

```{r, eval=FALSE}
Username <-  as.list(Leaders$Username)

x <- lapply(Username[1:10], function(x) userTimeline(x, n = 3200, includeRts = FALSE))

y <- lapply(x, function(x) twListToDF(x))
tweets <- tibble()
for(n in 1:10){
  tweets <- rbind(tweets, y[[n]])
}
```

With the tweets collected, we can start the analysis of what the various leaders are saying. My assumption is that they're all sticking to their talking points, and that evaluating any kind of emotion from the tweets will be fairly inaccurate as machines aren't so good at this type of text analysis yet.

A first necessary step is looking at the data, which showed me two big issues:

* Tweets are in multiple languages (Hindi, French, Spanish, English)
* Tweet counts vary widely between leaders


```{r, echo=FALSE}
tweets %>%
  group_by(screenName) %>%
  summarise(n = n()) %>%
  arrange(desc(n)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed"))

```


##Issue 1: multi-lingual tweets from all the leaders

There is another clear elephant in the ```twitteR``` analysis room: most of the leaders here aren't tweeting in English, and most are tweeting in multiple languages. This brings up a few options: 

1. Use a half-assed computer translation of all the tweets
2. Change my analysis and select only English-speaking world leaders
3. Continue with the analysis, and at a later date perform it using the multi-lingual version of the NRC Word-Emotion Association Lexicon created by the [National Research Council Canada (NRC)](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm)

I went with option 3, because once I saw that both ```googleLanguageR``` and ```translateR``` require creating an account with credit card, I realized its a task for another day to translate and process the tweets. As an aside, I would love to use ```googleLanguageR``` which can both [detect and translate](https://cran.r-project.org/web/packages/googleLanguageR/vignettes/translation.html), and will explore this in a future post.

##Issue 2: Variation in twitter activity / data collected

Okay, so we can see that there's some pretty large variation between what the leaders are tweeting (when we don't include retweets). I'm not sure if this is because of how the API collects tweets in the list created, the limit per user, or because they all have drastically differing degrees of twitter activity.
  After testing the download with different amounts (n), I found that it was consistently not collected all tweets from all users when placed in the list, and when downloading individually it brought up the same amount (e.g. Justin Trudeau with only 69 tweets, dating back only to June 20, 2018, whereas he is one of the more avid tweeters on the list for the past several years). I intend to pursue this further, but for now want to get into the bread and butter.


#Tidying the tweets

Regardless of the issues within the dataset, there are still some interesting things which can be derived. Following the [tidytext](https://www.tidytextmining.com/preface.html) principles developed by [Julia Silge](https://twitter.com/juliasilge) and [David Robinson](https://twitter.com/drob), I first parsed the text to remove stopwords (e.g. "and", "the", "le", "les", etc.) in each of the four languages present (English, French, Spanish and Hindi):

```{r, message=FALSE, warning=FALSE}
stop_words_en <- stop_words

stop_words_fr <- read_csv("https://raw.githubusercontent.com/stopwords-iso/stopwords-fr/master/stopwords-fr.txt")
names(stop_words_fr) <- "mots"

stop_words_es <- read_csv("https://raw.githubusercontent.com/stopwords-iso/stopwords-es/master/stopwords-es.txt")
names(stop_words_es) <- "termino"

stop_words_hn <- read.csv("https://raw.githubusercontent.com/stopwords-iso/stopwords-hi/master/stopwords-hi.txt")
names(stop_words_hn) <- "शब्द"

```


Once having established what these are, I can begin the anti-joining (or filtering out) process with these stopwords and other letters and unwanted symbols with:

```{r, message=FALSE, warning=FALSE}
replace_reg <- "https://t.co/[A-Za-z\\d]+|http://[A-Za-z\\d]+|&amp;|&lt;|&gt;|RT|https"
unnest_reg <- "([^A-Za-z_\\d#@']|'(?![A-Za-z_\\d#@]))"

tidy_tweets <- tweets %>% 
  filter(!str_detect(text, "^RT")) %>%
  mutate(text = str_replace_all(text, replace_reg, "")) %>%
  unnest_tokens(word, text, token = "regex", pattern = unnest_reg) %>%
  filter(!word %in% stop_words$word, str_detect(word, "[a-z]")) %>%
  filter(!word %in% stop_words_fr$mots, str_detect(word, "[a-z]")) %>%
  filter(!word %in% stop_words_es$termino, str_detect(word, "[a-z]")) %>%
  filter(!word %in% stop_words_hn$`शब्द`  , str_detect(word, "[a-z]"))

```

And what this gives me is a word-by-word breakdown of every tweet, with the Pope and French President Macron coming out with the most individual words, still reflective of the error mentioned above. 

```{r}
tidy_tweets %>%
  group_by(screenName) %>%
  count() %>%
  arrange(desc(n)) %>%
  kable() %>%
  kable_styling(bootstrap_options = c("striped","responsive", full_width = FALSE, position = "float_right"))
```

One way to help even-out this high tweet-count differential (and therefore wordcount), is by limiting the timeframe from January 1st, 2017 to now, and by grouping the words on a monthly basis by setting a ```floor_date()```:

```{r, echo = FALSE, error=FALSE, warning=FALSE}
tweets_2017_18 <- tidy_tweets %>%
  mutate(time_floor = floor_date(created, unit = "1 month")) %>%
  mutate(month = date(time_floor)) %>%
  filter(month > "2017-01-01")

ggplot(tweets_2017_18, aes(x = month, fill = screenName)) +
  geom_histogram(position = "identity", bins = 20, show.legend = FALSE) +
  facet_wrap(~screenName, ncol = 2) +
  theme_bw(base_family = "Lato") +
  theme(axis.title = element_text(size = 10)) +
  theme(legend.text = element_text(size = 10)) +
  theme(legend.title = element_text(size = 10)) +
  theme(axis.ticks = element_blank())  +
  theme(panel.border = element_blank()) + 
  theme(axis.line = element_blank()) +
  theme(panel.grid = element_blank())+
  theme(axis.text.x = element_text(angle = 90, vjust = 0.7))

```

Looking at the tweets since 2017, it's clear how the gap of tweets collected impacts the counts of world leaders, but in the least it provides an idea of the availability and quality of data present. 

##Looking at sentiment of all leaders, by counts

Looking at frequencies of words used, we can get an idea of what words are being used as raw counts, but going deeper into the meaning of these words requires using the NRC emoticon [lexicon](http://saifmohammad.com/WebPages/NRC-Emotion-Lexicon.htm). While it is also available in over [40 languages](http://saifmohammad.com/WebPages/AccessResource.htm), at this point I'll limit it's use to English and explore the multi-lingual analysis for another post.

```{r, message=FALSE}
#join the tweets library to the sentiment library, keeping only the sentiment-based words
sentiment_tweets_NRC <- tweets_2017_18 %>%
  inner_join(get_sentiments("nrc")) %>%
  select(sentiment, everything())
```


Graphically, these can be well-represented using the ```ggridges()``` package: 
```{r, message=FALSE, warning=FALSE}

pal <- wes_palette(6, name = "GrandBudapest1", type = "continuous")

sentiment_tweets_NRC %>%
  filter(sentiment %in% c("joy", "trust", "anticipation", 
                          "anger", "fear", "sadness")) %>%
  ggplot(aes(x = month, y = sentiment, fill = sentiment)) +
  geom_density_ridges(alpha = 0.8, show.legend = FALSE) +
  labs(x = "", y = "", title = "World Leader Tweet Sentiments",
       subtitle = "") +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_date() +
  scale_fill_manual(values = pal) +
  theme_ridges(grid = TRUE) +
  theme(plot.title = element_text(size = 22, hjust = -0.2),
        plot.subtitle = element_text(size = 18, face = "italic"),
        axis.text.y = element_text(size = 15, face = "bold"))
```

There isn't so much of a pattern of emotional change, rather a pattern of increased usage (because we are only looking at counts of all leaders). However, when looking at the leaders individually, we begin to see something more reflective occuring, particularly for the leaders with the most tweets collected:


```{r, echo=FALSE, warning = FALSE, message=FALSE}
pal_pos <- wes_palette(3, name = "FantasticFox1", type = "continuous")
pal_neg <- wes_palette(3, name = "Darjeeling2", type = "continuous")

sentiment_tweets_NRC %>%
  filter(sentiment %in% c("joy", "trust", "anticipation")) %>%
  filter(screenName %in% c("EmmanuelMacron", "Pontifex", "RT_Erdogan", "QueenRania", "CFKArgentina", "mbachelet")) %>%
  ggplot(aes(x = month, y = sentiment, fill = sentiment)) +
  geom_density_ridges(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~screenName, ncol = 2) +
    labs(x = "", y = "", title = "",
       subtitle = "\nPositive Sentiments") +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_date() +
  scale_fill_manual(values = pal_pos) +
  theme_ridges(grid = FALSE) +
  theme(plot.title = element_text(size = 22, hjust = -0.2),
        plot.subtitle = element_text(size = 18, face = "italic"),
        axis.text.y = element_text(size = 15, face = "bold"))

sentiment_tweets_NRC %>%
  filter(sentiment %in% c("anger", "fear", "sadness")) %>%
  filter(screenName %in% c("EmmanuelMacron", "Pontifex", "RT_Erdogan", "QueenRania", "CFKArgentina", "mbachelet")) %>%
  ggplot(aes(x = month, y = sentiment, fill = sentiment)) +
  geom_density_ridges(alpha = 0.8, show.legend = FALSE) +
  facet_wrap(~screenName, ncol = 2) +
  labs(x = "", y = "", title = "",
       subtitle = "\nNegative Sentiments") +
  scale_y_discrete(expand = c(0.01, 0)) +
  scale_x_date() +
  scale_fill_manual(values = pal_neg) +
  theme_ridges(grid = FALSE) +
  theme(plot.title = element_text(size = 22, hjust = -0.2),
        plot.subtitle = element_text(size = 18, face = "italic"),
        axis.text.y = element_text(size = 15, face = "bold"))
```

Something interesting we can see is a clear increase in "negative" word usage by Erdogan leading up to his re-election, decreasing usage of words associated with anger by Queen Rania of Jordan, and spikes of words associated with sadness and fear by ex-President Bachelet of Chile around the time her dual-term predidency ended. 

This is really just the tip of the iceberg when it comes to text analysis, tidying, and text interpretation with sentiment analysis. When looking closer at the data, it is apparent that there are still large gaps in determining sentiment from words extracted from tweets, and this post is far from taking a novel approach to this analysis. Next time, I anticipate performing this multi-lingually, digging deeper into word usage, and quality-checking the dataset.



### Acknowledgements and references

For the [twitteR](https://cran.r-project.org/web/packages/twitteR/twitteR.pdf)package, which has been indispensible for this and thousands of other similar "tweet" explorations;

For the methodology and general workflow found in the [text mining with R](https://www.tidytextmining.com/) tutorial, developed by [Julia Silge](https://twitter.com/juliasilge) and [David Robinson](https://twitter.com/drob)

This application/product/tool makes use of the NRC-Word Emotion Association Lexicon, created by Saif M. Mohammad and Peter D. Turney at the National Research Council Canada.

And for giving the idea, and providing the base code with the ```ggridges``` package, I thank [Grace Lawley](https://gracelawley-cs631.netlify.com/project/final_vis/), a student of [Dr. Alison Hill](https://twitter.com/apreshill)


